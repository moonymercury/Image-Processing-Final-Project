import os
import argparse
import json
from glob import glob

import cv2
import numpy as np
from sklearn.model_selection import train_test_split

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader

from umamba_unet import UMambaUNet
from losses_cldice import DiceBCELoss, DiceClDiceLoss, DiceLoss
import matplotlib.pyplot as plt
from tqdm import tqdm
# ----------------- Dataset -----------------
class MixedArcadeDataset(Dataset):
    """
    ä¸ä½¿ç”¨ alphaï¼Œä¸åš pseudo filteringã€‚
    pseudo label = {stem}_mask.png (png æ ¼å¼)
    """
    def __init__(self, img_dir, gt_dir, pseudo_dir, ids, use_pseudo=False, augment=False):
        self.img_dir = img_dir
        self.gt_dir = gt_dir
        self.pseudo_dir = pseudo_dir
        self.ids = ids
        self.use_pseudo = use_pseudo
        self.augment = augment

    def __len__(self):
        return len(self.ids)     # <â”€â”€ é€™è¡Œæ˜¯ä½ ç¼ºå°‘çš„

    def __getitem__(self, idx):
        stem = self.ids[idx]
        img_path = os.path.join(self.img_dir, f"{stem}.png")

        if self.use_pseudo:
            mask_path = os.path.join(self.pseudo_dir, f"{stem}_mask.png")
        else:
            mask_path = os.path.join(self.gt_dir, f"{stem}_mask.png")

        img = cv2.imread(img_path, 0).astype(np.float32) / 255.0
        mask = cv2.imread(mask_path, 0)
        mask = (mask > 127).astype(np.float32)

        img = np.expand_dims(img, 0)
        mask = np.expand_dims(mask, 0)

        return torch.from_numpy(img), torch.from_numpy(mask)

class ArcadeDataset(Dataset):
    def __init__(self, img_dir, mask_dir, ids, augment=False):
        self.img_dir = img_dir
        self.mask_dir = mask_dir
        self.ids = ids
        self.augment = augment

    def __len__(self):
        return len(self.ids)

    def _load_image(self, path):
        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
        if img is None:
            raise RuntimeError(f"Failed to read image: {path}")
        img = img.astype(np.float32) / 255.0  # [0,1]
        img = np.expand_dims(img, axis=0)     # (1,H,W)
        return img

    def _load_mask(self, path):
        m = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
        if m is None:
            raise RuntimeError(f"Failed to read mask: {path}")
        m = (m > 127).astype(np.float32)      # 0/1
        m = np.expand_dims(m, axis=0)
        return m

    def __getitem__(self, idx):
        stem = self.ids[idx]
        img_path = os.path.join(self.img_dir, f"{stem}.png")
        mask_path = os.path.join(self.mask_dir, f"{stem}_mask.png")

        img = self._load_image(img_path)
        mask = self._load_mask(mask_path)

        if self.augment:
            if np.random.rand() < 0.5:
                img = np.flip(img, axis=2).copy()
                mask = np.flip(mask, axis=2).copy()
            if np.random.rand() < 0.5:
                img = np.flip(img, axis=1).copy()
                mask = np.flip(mask, axis=1).copy()

        img = torch.from_numpy(img)   # (1,H,W)
        mask = torch.from_numpy(mask) # (1,H,W)
        return img, mask


# ----------------- Metrics & TTA -----------------
def dice_coeff(logits, targets, eps=1e-6):
    probs = torch.sigmoid(logits)
    probs = (probs > 0.5).float()
    probs = probs.view(probs.size(0), -1)
    targets = targets.view(targets.size(0), -1)

    inter = (probs * targets).sum(dim=1)
    denom = probs.sum(dim=1) + targets.sum(dim=1)
    dice = (2 * inter + eps) / (denom + eps)
    return dice.mean().item()


def tta_predict(model, imgs):
    """imgs: (B,1,H,W)"""
    with torch.no_grad():
        preds = []

        # identity
        logits = model(imgs)
        preds.append(torch.sigmoid(logits))

        # hflip
        h = torch.flip(imgs, dims=[3])
        logits_h = model(h)
        logits_h = torch.flip(logits_h, dims=[3])
        preds.append(torch.sigmoid(logits_h))

        # vflip
        v = torch.flip(imgs, dims=[2])
        logits_v = model(v)
        logits_v = torch.flip(logits_v, dims=[2])
        preds.append(torch.sigmoid(logits_v))

        # rot90
        r = torch.rot90(imgs, k=1, dims=[2, 3])
        logits_r = model(r)
        logits_r = torch.rot90(logits_r, k=-1, dims=[2, 3])
        preds.append(torch.sigmoid(logits_r))

        prob = torch.stack(preds, dim=0).mean(dim=0)
    return prob


# ----------------- Training / Eval loops -----------------
def validate_one_epoch(model, loader, loss_fn, device):
    model.eval()
    val_loss = 0

    progress = tqdm(loader, desc="Validating", ncols=100)

    with torch.no_grad():
        for imgs, masks in progress:
            imgs, masks = imgs.to(device), masks.to(device)
            logits = model(imgs)
            loss = loss_fn(logits, masks)

            val_loss += loss.item()
            progress.set_postfix(val_loss=f"{loss.item():.4f}")

    return val_loss / len(loader)


def train_one_epoch(model, loader, optimizer, loss_fn, device):
    model.train()
    epoch_loss = 0

    progress = tqdm(loader, desc="Training", ncols=100)

    for imgs, masks in progress:
        imgs, masks = imgs.to(device), masks.to(device)

        optimizer.zero_grad()
        logits = model(imgs)
        loss = loss_fn(logits, masks)
        loss.backward()
        optimizer.step()

        epoch_loss += loss.item()

        # æ›´æ–°é€²åº¦æ¢æ–‡å­—
        progress.set_postfix(loss=f"{loss.item():.4f}")

    return epoch_loss / len(loader)

def eval_one_epoch(model, loader, loss_fn, device, use_tta=False):
    model.eval()
    running = 0.0
    dices = []
    with torch.no_grad():
        for imgs, masks in loader:
            imgs = imgs.to(device)
            masks = masks.to(device)

            if use_tta:
                probs = tta_predict(model, imgs)
                logits = torch.logit(probs.clamp(1e-6, 1 - 1e-6))
            else:
                logits = model(imgs)
            loss = loss_fn(logits, masks)
            running += loss.item() * imgs.size(0)
            dices.append(dice_coeff(logits, masks))
    return running / len(loader.dataset), float(np.mean(dices)) if dices else 0.0


# ----------------- Pseudo-label generation -----------------
def generate_pseudo_labels(model, img_dir, pseudo_dir, device):
    os.makedirs(pseudo_dir, exist_ok=True)
    model.eval()
    with torch.no_grad():
        for img_path in sorted(glob(os.path.join(img_dir, "*.png"))):
            img_id = os.path.splitext(os.path.basename(img_path))[0]

            img = cv2.imread(img_path, 0).astype(np.float32) / 255.0
            img_tensor = torch.from_numpy(img).unsqueeze(0).unsqueeze(0).to(device)

            pred = torch.sigmoid(model(img_tensor))[0,0].cpu().numpy()

            # save soft mask
            np.save(os.path.join(pseudo_dir, f"{img_id}_mask_prob.npy"), pred)

            # For visualization only
            mask = (pred > 0.5).astype(np.uint8) * 255
            cv2.imwrite(os.path.join(pseudo_dir, f"{img_id}_mask.png"), mask)

        print(f"[INFO] Pseudo labels saved to {pseudo_dir}")

class SimpleImageDataset(Dataset):
    """ç”¨æ–¼ç”¢ç”Ÿ pseudo-label æ™‚ï¼Œåªéœ€è¦å½±åƒä¸éœ€è¦ GTã€‚"""
    def __init__(self, img_dir, ids):
        self.img_dir = img_dir
        self.ids = ids

    def __len__(self):
        return len(self.ids)

    def __getitem__(self, idx):
        stem = self.ids[idx]
        path = os.path.join(self.img_dir, f"{stem}.png")
        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
        if img is None:
            raise RuntimeError(f"Failed to read: {path}")
        img = img.astype(np.float32) / 255.0
        img = np.expand_dims(img, 0)
        img = torch.from_numpy(img)
        return img, stem


# ----------------- Main -----------------
def parse_args():
    p = argparse.ArgumentParser()
    p.add_argument("--data_root", type=str, required=True,
                   help="ARCADE è³‡æ–™å¤¾æ ¹ç›®éŒ„ï¼Œä¾‹å¦‚ /workspace/ARCADE")
    p.add_argument("--out_dir", type=str, default="./umamba_output")
    p.add_argument("--epochs", type=int, default=100)
    p.add_argument("--batch_size", type=int, default=4)
    p.add_argument("--lr", type=float, default=1e-3)
    p.add_argument("--experiment", type=str, default="baseline",
                   choices=["baseline", "pseudo", "cldice", "pseudo_cldice", "final"],
                   help="å°æ‡‰ I~V äº”çµ„å¯¦é©—")
    p.add_argument("--val_ratio", type=float, default=0.1)
    p.add_argument("--seed", type=int, default=42)
    p.add_argument("--start_fold", type=int, default=0)
    p.add_argument("--baseline_ckpt", type=str,
                   help="å·²è¨“ç·´å¥½çš„ baseline æ¬Šé‡ï¼Œç”¨æ–¼ç”¢ç”Ÿ pseudo-label æˆ– final æ¨¡å‹å¾®èª¿")
    return p.parse_args()


def main():
    args = parse_args()
    # NEW â†“â†“â†“ ä¿è­‰ exp_A / exp_B / exp_AB / exp_ABC éƒ½æœƒäº‹å…ˆå»ºç«‹
    os.makedirs(args.out_dir, exist_ok=True)

    torch.manual_seed(args.seed)
    np.random.seed(args.seed)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"[INFO] Using device: {device}")

    img_dir = os.path.join(args.data_root, "images")
    gt_dir = os.path.join(args.data_root, "masks")
    pseudo_dir = os.path.join(args.data_root, "pseudo")

    # --------- æ”¶é›†è³‡æ–™ ID ---------
    img_files = sorted(glob(os.path.join(img_dir, "*.png")))
    ids = [os.path.splitext(os.path.basename(f))[0] for f in img_files]
    if len(ids) == 0:
        raise RuntimeError(f"No images found in {img_dir}")

    # --------- Loss / Attention è¨­å®š ---------
    if args.experiment in ["baseline", "pseudo"]:
        loss_fn = DiceBCELoss()
        use_cldice = False
    elif args.experiment in ["cldice", "pseudo_cldice", "final"]:
        loss_fn = DiceClDiceLoss()
        use_cldice = True
    else:
        loss_fn = DiceBCELoss()
        use_cldice = False

    use_tta = (args.experiment == "final")

    print(f"[INFO] Experiment = {args.experiment}")
    print(f"       Loss = {'Dice+BCE' if not use_cldice else 'Dice+clDice'}")
    
    # --------- æ±ºå®šä½¿ç”¨ GT æˆ– pseudo ---------
    if args.experiment in ["baseline", "cldice"]:
        train_mask_source = "GT"
        print("[INFO] Using original GT masks.")
    elif args.experiment in ["pseudo_cldice", "pseudo", "final"]:
        train_mask_source = "MIXED"   # GT + pseudo æ··åˆ
    else:
        train_mask_source = "PSEUDO"

    # ========================================================
    # ğŸ”¥ 5-FOLD CROSS VALIDATION
    # ========================================================
    from sklearn.model_selection import KFold
    kf = KFold(n_splits=5, shuffle=True, random_state=args.seed)

    all_fold_dice = []

    for fold, (train_idx, val_idx) in enumerate(kf.split(ids)):
        if fold < args.start_fold:
            continue
        
        print("\n" + "=" * 60)
        print(f"ğŸ”¥ Starting Fold {fold+1}/5")
        print("=" * 60)

        train_ids = [ids[i] for i in train_idx]
        val_ids = [ids[i] for i in val_idx]

        # --------------------------------------------
        # å»ºç«‹ datasetï¼šæ ¹æ“š mask_source æ±ºå®šä½¿ç”¨ GT / pseudo / MIXED
        # --------------------------------------------
        if train_mask_source == "GT":
            train_set = ArcadeDataset(img_dir, gt_dir, train_ids, augment=True)

        elif train_mask_source == "PSEUDO":
            train_set = ArcadeDataset(img_dir, pseudo_dir, train_ids, augment=True)

        elif train_mask_source == "MIXED":
            # é€™è£¡é¸æ“‡ 50% pseudo, 50% GTï¼Œå¯è‡ªè¡Œèª¿æ•´ alpha
            train_set = MixedArcadeDataset(img_dir, gt_dir, pseudo_dir, train_ids, use_pseudo=True, augment=True)

        # Validation ä¸€å¾‹ç”¨ GTï¼Œé¿å… pseudo å½±éŸ¿è©•ä¼°
        val_set = ArcadeDataset(img_dir, gt_dir, val_ids, augment=False)

        train_loader = DataLoader(train_set, batch_size=args.batch_size,
                                  shuffle=True, num_workers=4, pin_memory=True)
        val_loader = DataLoader(val_set, batch_size=args.batch_size,
                                shuffle=False, num_workers=2, pin_memory=True)

        # -------- å»ºç«‹æ¨¡å‹ --------
        model = UMambaUNet(in_channels=1, num_classes=1)
        model.to(device)
        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)

        # -------- Early Stopping --------
        best_dice = 0.0
        patience = 15
        patience_counter = 0

        ckpt_path = os.path.join(args.out_dir, f"fold{fold}_best.pth")
        history = {"train_loss": [], "val_loss": []}

        # ========================================================
        # ğŸ”¥ Training Loop (with early stopping)
        # ========================================================
        for epoch in range(1, args.epochs + 1):
            print(f"\n===== Fold {fold+1} | Epoch {epoch}/{args.epochs} =====")

            train_loss = train_one_epoch(model, train_loader, optimizer, loss_fn, device)
            val_loss, val_dice = eval_one_epoch(model, val_loader, loss_fn, device, use_tta=use_tta)

            print(f"[F{fold}][Epoch {epoch}] Train {train_loss:.4f} | Val {val_loss:.4f} | Dice {val_dice:.4f}")

            history["train_loss"].append(train_loss)
            history["val_loss"].append(val_loss)

            # --------- åˆ¤æ–·æ˜¯å¦æ›´æ–° best model ---------
            if val_dice > best_dice:
                best_dice = val_dice
                patience_counter = 0
                torch.save(model.state_dict(), ckpt_path)
                print(f"[INFO] New best Dice {best_dice:.4f} â†’ saved to {ckpt_path}")
            else:
                patience_counter += 1
                print(f"[INFO] No improvement ({patience_counter}/{patience})")

            # --------- Early stopping trigger ---------
            if patience_counter >= patience:
                print(f"â›” Early stopping at epoch {epoch}")
                break

        all_fold_dice.append(best_dice)

        # --------- ç•« loss curve ---------
        plt.figure(figsize=(7,5))
        plt.plot(history["train_loss"], label="Train")
        plt.plot(history["val_loss"], label="Val")
        plt.title(f"Fold {fold} Loss Curve")
        plt.xlabel("Epoch")
        plt.ylabel("Loss")
        plt.legend()
        plt.grid()
        plt.savefig(os.path.join(args.out_dir, f"loss_curve_fold{fold}.png"), dpi=200)
        plt.close()

    # ========================================================
    # ğŸ”¥ å…¨éƒ¨ fold çµæœ
    # ========================================================
    print("\n===============================")
    print("ğŸ”¥ 5-FOLD RESULTS")
    print("===============================")
    for f, dice in enumerate(all_fold_dice):
        print(f"Fold {f}: Dice = {dice:.4f}")
    print(f"\nğŸ”¥ Mean Dice = {np.mean(all_fold_dice):.4f}")

    print("[DONE] 5-fold cross validation finished.")

if __name__ == "__main__":
    main()
